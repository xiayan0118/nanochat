{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca44500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path so we can import nanochat\n",
    "import sys\n",
    "sys.path.insert(0, \"/Users/yanxia/code/lab/nanochat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07d2ea13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 16:07:21,590 - nanochat.common - \u001b[32m\u001b[1mINFO\u001b[0m - Distributed world size: 1\n"
     ]
    }
   ],
   "source": [
    "from nanochat.common import compute_init, compute_cleanup, get_dist_info, print0\n",
    "\n",
    "compute_init(\"mps\")\n",
    "info = get_dist_info()\n",
    "# print0(f\"Rank: {info.rank}, World: {info.world_size}\")\n",
    "compute_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e8c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanochat.tokenizer import RustBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b66c7259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 16:07:28,110 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Processing sequences from iterator (buffer_size: 8192)\n",
      "2026-01-12 16:07:28,113 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Processed 300 sequences total, 12 unique\n",
      "2026-01-12 16:07:28,113 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Starting BPE training: 247 merges to compute\n",
      "2026-01-12 16:07:28,113 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Computing initial pair counts from 12 unique sequences\n",
      "2026-01-12 16:07:28,114 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Building heap with 41 unique pairs\n",
      "2026-01-12 16:07:28,114 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Starting merge loop\n",
      "2026-01-12 16:07:28,115 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m1%\u001b[0m (3/247 merges) - Last merge: (32, 98) -> 258 (frequency: 100)\n",
      "2026-01-12 16:07:28,115 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m2%\u001b[0m (5/247 merges) - Last merge: (32, 108) -> 260 (frequency: 100)\n",
      "2026-01-12 16:07:28,116 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m3%\u001b[0m (8/247 merges) - Last merge: (72, 101) -> 263 (frequency: 100)\n",
      "2026-01-12 16:07:28,116 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m4%\u001b[0m (10/247 merges) - Last merge: (84, 104) -> 265 (frequency: 100)\n",
      "2026-01-12 16:07:28,116 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m5%\u001b[0m (13/247 merges) - Last merge: (99, 107) -> 268 (frequency: 100)\n",
      "2026-01-12 16:07:28,117 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m6%\u001b[0m (15/247 merges) - Last merge: (105, 268) -> 270 (frequency: 100)\n",
      "2026-01-12 16:07:28,117 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m7%\u001b[0m (18/247 merges) - Last merge: (110, 257) -> 273 (frequency: 100)\n",
      "2026-01-12 16:07:28,117 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m8%\u001b[0m (20/247 merges) - Last merge: (111, 119) -> 275 (frequency: 100)\n",
      "2026-01-12 16:07:28,117 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m9%\u001b[0m (23/247 merges) - Last merge: (117, 110) -> 278 (frequency: 100)\n",
      "2026-01-12 16:07:28,118 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m10%\u001b[0m (25/247 merges) - Last merge: (256, 276) -> 280 (frequency: 100)\n",
      "2026-01-12 16:07:28,118 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m11%\u001b[0m (28/247 merges) - Last merge: (258, 277) -> 283 (frequency: 100)\n",
      "2026-01-12 16:07:28,118 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m12%\u001b[0m (30/247 merges) - Last merge: (260, 269) -> 285 (frequency: 100)\n",
      "2026-01-12 16:07:28,118 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m13%\u001b[0m (33/247 merges) - Last merge: (263, 272) -> 288 (frequency: 100)\n",
      "2026-01-12 16:07:28,119 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m14%\u001b[0m (35/247 merges) - Last merge: (265, 101) -> 290 (frequency: 100)\n",
      "2026-01-12 16:07:28,119 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m15%\u001b[0m (38/247 merges) - Last merge: (285, 291) -> 293 (frequency: 100)\n",
      "2026-01-12 16:07:28,119 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Progress: \u001b[1m16%\u001b[0m (40/247 merges) - Last merge: (288, 111) -> 295 (frequency: 100)\n",
      "2026-01-12 16:07:28,119 - rustbpe - \u001b[32m\u001b[1mINFO\u001b[0m - Finished training: 41 merges completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hello machine learning world!\n",
      "Tokens: [295, 32, 109, 97, 267, 282, 293, 294, 33]\n",
      "Decoded: Hello machine learning world!\n",
      "Rendered: ([297, 298, 87, 104, 97, 116, 284, 32, 50, 43, 50, 63, 299, 300, 52, 301], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Train tiny tokenizer\n",
    "texts = [\"Hello world!\", \"The quick brown fox.\", \"Machine learning is fun.\"] * 100\n",
    "tok = RustBPETokenizer.train_from_iterator(iter(texts), vocab_size=512)\n",
    "\n",
    "# Test encoding/decoding\n",
    "text = \"Hello machine learning world!\"\n",
    "ids = tok.encode(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Tokens: {ids}\")\n",
    "print(f\"Decoded: {tok.decode(ids)}\")\n",
    "\n",
    "# Test conversation rendering\n",
    "conv = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is 2+2?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"4\"},\n",
    "    ]\n",
    "}\n",
    "rendered = tok.render_conversation(conv)\n",
    "print(f\"Rendered: {rendered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9ab5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "def find_num_heads(model_dim, target_head_dim=128):\n",
    "    # Find num_heads that divides model_dim evenly, with head_dim closest to target.\n",
    "    ideal = max(1, round(model_dim / target_head_dim))\n",
    "    for offset in range(model_dim):\n",
    "        for candidate in [ideal + offset, ideal - offset]:\n",
    "            if candidate > 0 and model_dim % candidate == 0:\n",
    "                return candidate\n",
    "    return 1\n",
    "\n",
    "print(find_num_heads(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c83d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanochat (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
